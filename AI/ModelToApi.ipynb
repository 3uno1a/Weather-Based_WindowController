{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "545554ba",
   "metadata": {},
   "source": [
    "# 감성 분석"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "5f29f1d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install requests\n",
    "# !pip install numpy\n",
    "# !pip install prometheus_api_client\n",
    "# !pip install scikit-learn\n",
    "# !pip install matplotlib\n",
    "# !pip install pyupbit \n",
    "# !pip install pydot"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d3f154c3",
   "metadata": {},
   "source": [
    "### RestAPI에 저장된 텍스트 가져오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9233f0d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "API GET 요청 성공\n",
      "우리 모두 힘내요\n"
     ]
    }
   ],
   "source": [
    "import requests \n",
    "def get_stt():\n",
    "    url_speech = 'http://172.30.1.111:8000/api/speech/'\n",
    "\n",
    "    response = requests.get(url_speech)\n",
    "    if response.status_code == 200:\n",
    "        data = response.json()\n",
    "        print(\"API GET 요청 성공\")\n",
    "        return data[0]['text']\n",
    "    else:\n",
    "        print(\"API GET 요청 실패:\", response.status_code)\n",
    "        return None\n",
    "    \n",
    "text_data = get_stt()\n",
    "\n",
    "print(text_data)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "87887476",
   "metadata": {},
   "source": [
    "### JSON으로 저장된 모델 불러와서 긍정 1 : 부정 0 으로 나타내기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8be3f8cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "from konlpy.tag import Okt\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "import requests\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1ef672c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 703ms/step\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "okt = Okt()\n",
    "tokenizer  = Tokenizer()\n",
    "\n",
    "DATA_CONFIGS = './data2/LSTM/data_configs.json'\n",
    "prepro_configs = json.load(open(DATA_CONFIGS,'r'))\n",
    "word_vocab =prepro_configs['vocab']\n",
    "\n",
    "tokenizer.fit_on_texts(word_vocab)\n",
    "\n",
    "MAX_LENGTH = 30 #문장최대길이\n",
    "\n",
    "sentence = text_data\n",
    "sentence = re.sub(r'[^ㄱ-ㅎㅏ-ㅣ가-힣\\\\s ]','', sentence)\n",
    "stopwords = ['은','는','이','가','하','아','것','들','의','있','되','수','보','주','등','한'] # 불용어 추가할 것이 있으면 이곳에 추가\n",
    "sentence = okt.morphs(sentence, stem=True) # 토큰화\n",
    "sentence = [word for word in sentence if not word in stopwords] # 불용어 제거\n",
    "vector  = tokenizer.texts_to_sequences(sentence)\n",
    "pad_new = pad_sequences(vector, maxlen = MAX_LENGTH) # 패딩\n",
    "\n",
    "# print(pad_new)\n",
    "from tensorflow.keras.models import load_model\n",
    "model = load_model('./data2/LSTM/model.h5') #모델 불러오기\n",
    "# model.load_weights('./data2/LSTM/model.h5') #모델 불러오기\n",
    "predictions = model.predict(pad_new)\n",
    "predictions = float(predictions.squeeze(-1)[1])\n",
    "\n",
    "result = ()\n",
    "\n",
    "if(predictions > 0.5):\n",
    "    # print(1) \n",
    "    result = 1\n",
    "else:\n",
    "    print(0)\n",
    "    result = 0\n",
    "# if(predictions > 0.5):\n",
    "#   print(\"{:.2f}% 확률로 긍정 \\n\".format(predictions * 100))\n",
    "# else:\n",
    "#   print(\"{:.2f}% 확률로 부정 \\n\".format((1 - predictions) * 100))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a49af419",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['우리', '모두', '힘내다']\n"
     ]
    }
   ],
   "source": [
    "# print(pad_new)\n",
    "# print(vector)\n",
    "print(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "b5ffbce4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "API POST 요청 성공\n"
     ]
    }
   ],
   "source": [
    "result = predictions\n",
    "\n",
    "def post_emotion(result):\n",
    "    url_emotion = 'http://127.0.0.1:8000/api/emotion/'\n",
    "    data_emotion = {\n",
    "        'emotion': result,\n",
    "    }\n",
    "    headers = {'Content-Type': 'application/json'}\n",
    "\n",
    "    response = requests.post(url_emotion, data=json.dumps(data_emotion), headers=headers)\n",
    "    if response.status_code == 201:\n",
    "        print(\"API POST 요청 성공\")\n",
    "    else:\n",
    "        print(\"API POST 요청 실패\")\n",
    "\n",
    "post_emotion(result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
